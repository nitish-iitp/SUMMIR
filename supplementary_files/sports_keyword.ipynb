{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Script to generate a sports sentiment database with 1,000+ words\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import wordnet as wn\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from afinn import Afinn\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize Sentiment Analyzers\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "afinn = Afinn()\n",
    "\n",
    "# Base exciting sports keywords\n",
    "exciting_keywords = {\n",
    "    \"win\", \"victory\", \"champion\", \"record-breaking\", \"comeback\", \"triumph\",\n",
    "    \"historic\", \"golden\", \"trophy\", \"medal\", \"legendary\", \"unbeatable\",\n",
    "    \"domination\", \"clutch\", \"buzzer-beater\", \"overtime\", \"upset\", \"shock\",\n",
    "    \"underdog\", \"grand slam\", \"stunning\", \"miracle\", \"epic\", \"thriller\",\n",
    "    \"dynasty\", \"streak\", \"MVP\", \"all-star\", \"perfect game\", \"no-hitter\",\n",
    "    \"hat-trick\", \"slam dunk\", \"three-pointer\", \"fast break\", \"breakaway\",\n",
    "    \"goal\", \"penalty\", \"overtime winner\", \"shootout\", \"free kick\",\n",
    "    \"corner kick\", \"bicycle kick\", \"walk-off\", \"home run\", \"strikeout\",\n",
    "    \"touchdown\", \"interception\", \"pick-six\", \"Hail Mary\", \"field goal\",\n",
    "    \"red zone\", \"overtime thriller\", \"power play\", \"match-winner\",\n",
    "    \"serve ace\", \"match point\", \"hole-in-one\", \"photo finish\", \"drama\",\n",
    "    \"intensity\", \"highlight reel\", \"record-setting\", \"career-defining\",\n",
    "    \"legacy\", \"unstoppable\", \"grit\", \"perseverance\", \"controversy\",\n",
    "    \"scandal\", \"injury\", \"comeback story\", \"retirement\", \"farewell\",\n",
    "    \"dream season\", \"superstar\", \"rivalry\", \"showdown\", \"title defense\",\n",
    "    \"last-second heroics\", \"GOAT\", \"dominating performance\", \"instant classic\"\n",
    "}\n",
    "\n",
    "# Function to get sports-related words from WordNet\n",
    "def get_related_words(base_words, max_words=500):\n",
    "    related_words = set(base_words)\n",
    "    \n",
    "    for word in base_words:\n",
    "        for syn in wn.synsets(word):\n",
    "            for lemma in syn.lemmas():\n",
    "                related_words.add(lemma.name().replace('_', ' '))\n",
    "                if len(related_words) >= max_words:\n",
    "                    return list(related_words)\n",
    "\n",
    "    return list(related_words)\n",
    "\n",
    "# Expand keywords using WordNet\n",
    "expanded_keywords = get_related_words(exciting_keywords, max_words=5000)\n",
    "\n",
    "# Function to scrape sports-related words from sports news websites\n",
    "def scrape_sports_words(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    words = set()\n",
    "    for word in soup.get_text().split():\n",
    "        if len(word) > 3 and word.isalpha():\n",
    "            words.add(word.lower())\n",
    "\n",
    "    return words\n",
    "\n",
    "# Sports news sources\n",
    "sports_urls = [\n",
    "    \"https://www.espn.com\",\n",
    "    \"https://www.bbc.com/sport\",\n",
    "    \"https://www.fifa.com\",\n",
    "    \"https://www.nba.com\",\n",
    "    \"https://www.mlssoccer.com\"\n",
    "]\n",
    "\n",
    "# Scrape words from multiple sources\n",
    "scraped_words = set()\n",
    "for url in sports_urls:\n",
    "    scraped_words.update(scrape_sports_words(url))\n",
    "\n",
    "# Function to generate sports-related phrases\n",
    "import random\n",
    "\n",
    "sports_nouns = [\"goal\", \"match\", \"tournament\", \"champion\", \"victory\", \"team\"]\n",
    "sports_adjectives = [\"exciting\", \"record-breaking\", \"unbeatable\", \"legendary\"]\n",
    "sports_verbs = [\"win\", \"score\", \"compete\", \"dominate\", \"race\", \"strike\"]\n",
    "\n",
    "generated_phrases = set()\n",
    "for _ in range(3000):  # Generate 3000 random phrases\n",
    "    phrase = f\"{random.choice(sports_adjectives)} {random.choice(sports_nouns)}\"\n",
    "    generated_phrases.add(phrase)\n",
    "\n",
    "# Merge all sources of sports words\n",
    "all_sports_words = list(set(expanded_keywords) | scraped_words | generated_phrases)\n",
    "all_sports_words = all_sports_words[:10000]  # Limit to 10,000 words\n",
    "\n",
    "print(f\"Total Sports Words Collected: {len(all_sports_words)}\")\n",
    "\n",
    "# Function to get SentiWordNet sentiment score\n",
    "def get_sentiwordnet_score(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    if synsets:\n",
    "        synset = synsets[0]\n",
    "        reference_synset = wn.synsets(\"good\", pos=wn.ADJ)\n",
    "        if reference_synset:\n",
    "            return synset.wup_similarity(reference_synset[0]) or 0\n",
    "    return 0\n",
    "\n",
    "# Generate sentiment scores\n",
    "sports_sentiment_data = []\n",
    "for word in all_sports_words:\n",
    "    vader_score = vader.polarity_scores(word)[\"compound\"]\n",
    "    afinn_score = afinn.score(word)\n",
    "    sentiwordnet_score = get_sentiwordnet_score(word)\n",
    "\n",
    "    avg_score = (vader_score + afinn_score + (sentiwordnet_score * 10)) / 3  \n",
    "\n",
    "    sports_sentiment_data.append([word, vader_score, afinn_score, sentiwordnet_score, avg_score])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(sports_sentiment_data, columns=[\"Word\", \"VADER\", \"AFINN\", \"SentiWordNet\", \"AverageScore\"])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"sports_sentiment_expanded.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Sports Sentiment Database with 10,000+ words saved to 'sports_sentiment_expanded.csv' successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to sports_keywords.csv\n",
      "Data cleaning and normalization complete!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = \"sports_sentiment.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure all sentiment scores are positive\n",
    "df[[\"VADER\", \"AFINN\", \"SentiWordNet\", \"AverageScore\"]] = df[[\"VADER\", \"AFINN\", \"SentiWordNet\", \"AverageScore\"]].abs()\n",
    "\n",
    "# Normalize AFINN, SentiWordNet, and AverageScore by dividing by the max value in each column\n",
    "for col in [\"AFINN\", \"SentiWordNet\", \"AverageScore\"]:\n",
    "    max_value = df[col].max()\n",
    "    if max_value > 0:\n",
    "        df[col] = df[col] / max_value\n",
    "\n",
    "# Remove rows where AverageScore is 0\n",
    "df = df[df[\"AverageScore\"] > 0]\n",
    "\n",
    "# Sort by AverageScore in descending order\n",
    "df = df.sort_values(by=\"AverageScore\", ascending=False)\n",
    "\n",
    "# Save the cleaned and sorted data to a new CSV file\n",
    "output_file = \"sports_keywords.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Processed data saved to {output_file}\")\n",
    "print(\"Data cleaning and normalization complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
